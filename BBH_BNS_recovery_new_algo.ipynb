{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237c5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "import pycbc.filter\n",
    "from pycbc.filter import matched_filter\n",
    "from pycbc.waveform import get_td_waveform\n",
    "from pycbc.waveform import get_fd_waveform\n",
    "import numpy as np\n",
    "from pycbc.vetoes import power_chisq\n",
    "from pycbc.events.ranking import newsnr\n",
    "import pandas as pd\n",
    "from pycbc.filter import sigma\n",
    "import h5py\n",
    "from pycbc.types import timeseries\n",
    "from pycbc.types import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f57a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(psd_need):\n",
    "    \n",
    "    # The color of the noise matches a PSD which you provide\n",
    "    flow = 30.0\n",
    "    delta_f = 1.0 / 16\n",
    "    flen = int(2048 / delta_f) + 1\n",
    "    psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "\n",
    "    if (psd_need == True) :\n",
    "        pp.plot(psd.sample_frequencies,psd.data)\n",
    "        pp.loglog()\n",
    "        pp.xlim(30,2000)\n",
    "        pp.ylabel('$Strain^2 / Hz$')\n",
    "        pp.xlabel('Frequency (Hz)')\n",
    "        pp.show()\n",
    "\n",
    "\n",
    "    # Generate 256 seconds of noise at 4096 Hz\n",
    "    delta_t = 1.0 / 4096\n",
    "    tsamples = int(256/ delta_t)\n",
    "    ts = pycbc.noise.gaussian.noise_from_psd(tsamples,delta_t, psd, seed=127)\n",
    "    \n",
    "    \n",
    "    #plotting noise \n",
    "#     pp.plot(ts.sample_times, ts)\n",
    "#     pp.ylabel('Strain')\n",
    "#     pp.xlabel('Time (simport numpy as np\n",
    "\n",
    "#     pp.show()\n",
    "    \n",
    "\n",
    "    return ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f8bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_waveform(model,m1,m2,s1z,s2z,distance,time,l):\n",
    "    \n",
    "    from pycbc.detector import Detector\n",
    "    from pycbc.waveform import get_td_waveform\n",
    "\n",
    "\n",
    "   \n",
    "    ra = 1.7\n",
    "    dec = 1.7\n",
    "    pol = 0.2\n",
    "    inclination_1 = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # We can calcualate the antenna pattern for Hanford at\n",
    "    # the specific sky location\n",
    "    d = Detector(\"H1\")\n",
    "\n",
    "    # We get back the fp and fc antenna pattern weights.\n",
    "    fp, fc = d.antenna_pattern(ra, dec, pol, time)\n",
    "    #print(\"fp={}, fc={}\".format(fp, fc))\n",
    "\n",
    "    # These factors allow us to project a signal into what the detector would observe\n",
    "    # IMRPhenomPv2\n",
    "    # Generate the waveform for the BNS merger\n",
    "    hp_1, hc_1 = get_td_waveform(approximant=model,\n",
    "                             mass1=m1, mass2=m2,spin1z=s1z,spin2z=s2z,\n",
    "                             distance=distance, inclination=inclination_1,\n",
    "                             delta_t=1.0/4096, f_lower=30)\n",
    "\n",
    "    ## Apply the factors to get the detector frame strain\n",
    "    ht_1 = fp * hp_1 + fc * hc_1\n",
    "    \n",
    "    \n",
    "#     pp.plot(ht_1.sample_times, ht_1, label=l)\n",
    "#     pp.legend()\n",
    "#     pp.ylabel('Strain')\n",
    "#     pp.xlabel('Time')\n",
    "#     pp.grid()\n",
    "#     pp.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return ht_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ffdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(ht_1,ht_2,buffer):\n",
    "\n",
    "    if len(ht_1) < len(ht_2):\n",
    "        ht_small, ht_big = ht_1, ht_2\n",
    "    else:\n",
    "        ht_small, ht_big = ht_2, ht_1\n",
    "\n",
    "    dt = ht_small.delta_t\n",
    "   \n",
    "    \n",
    "    # make buffer int multiple of dt\n",
    "    buffer = np.round(buffer*ht_big.sample_rate)/ht_big.sample_rate\n",
    "    \n",
    "    \n",
    "    # elongate the long template to accomodate enough space on left\n",
    "    ht_big.resize(len(ht_big)+int(buffer*ht_big.sample_rate))\n",
    "#     pp.plot(ht_big.sample_times,ht_big)\n",
    "#     pp.show()\n",
    "    \n",
    "    # match small template\n",
    "    ht_small.resize(len(ht_big))\n",
    "#     pp.plot(ht_small.sample_times,ht_small)\n",
    "#     pp.show()\n",
    "    \n",
    "    \n",
    "    # correct the position after resizing\n",
    "    ht_big = ht_big.cyclic_time_shift(buffer)\n",
    "#     pp.plot(ht_big.sample_times,ht_big)\n",
    "#     pp.show()\n",
    "    \n",
    "    #Shifting the merger time\n",
    "    ht_small = ht_small.cyclic_time_shift(ht_small.start_time-ht_big.start_time-buffer)\n",
    "#     pp.plot(ht_small.sample_times,ht_small)\n",
    "#     pp.show()\n",
    "    \n",
    "    #Equating the start time of both signals\n",
    "    ht_small.start_time = ht_big.start_time\n",
    "   \n",
    "    \n",
    "    # resample to original sample rate\n",
    "    ht_big = ht_big.resample(dt)\n",
    "    ht_small = ht_small.resample(dt)\n",
    "    \n",
    "    \n",
    "\n",
    "    #Combining the signals\n",
    "    ht_total = ht_small + ht_big\n",
    "#     pp.plot(ht_total.sample_times,ht_total)\n",
    "#     pp.show()\n",
    "    return ht_total,ht_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cde12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject(ht_total,ts):\n",
    "    \n",
    "    #Resizing the signal\n",
    "    ht_total.resize(len(ts)) \n",
    "    \n",
    "    #Equating the start time\n",
    "    ht_total.start_time = ts.start_time\n",
    "    \n",
    "    #Injecting signal into noise\n",
    "    ts = ts.add_into(ht_total) \n",
    "    \n",
    "    #plotting the result\n",
    "#     pp.plot(ts.sample_times, ts)\n",
    "#     pp.xlabel('Time(s)')\n",
    "#     pp.ylabel('Strain')\n",
    "#     pp.grid()\n",
    "#     pp.show()\n",
    "    \n",
    "    return ts \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be640ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd_data(conditioned):\n",
    "\n",
    "    from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "    # Estimate the power spectral density\n",
    "\n",
    "    # We use 4 second samples of our time series in Welch method.\n",
    "    psd = conditioned.psd(4)\n",
    "\n",
    "    # Now that we have the psd we need to interpolate it to match our data\n",
    "    # and then limit the filter length of 1 / PSD. After this, we can\n",
    "    # directly use this PSD to filter the data in a controlled manner\n",
    "\n",
    "    psd = interpolate(psd, conditioned.delta_f)\n",
    "\n",
    "    # 1/PSD will now act as a filter with an effective length of 4 seconds\n",
    "    # Since the data has been highpassed above 30 Hz, and will have low values\n",
    "    # below this we need to informat the function to not include frequencies\n",
    "    # below this frequency. \n",
    "    psd = inverse_spectrum_truncation(psd, int(4 * conditioned.sample_rate),\n",
    "                                      low_frequency_cutoff=30)\n",
    "\n",
    "#     pp.loglog(psd.sample_frequencies, psd)\n",
    "#     pp.ylabel('$Strain^2 / Hz$')\n",
    "#     pp.xlabel('Frequency (Hz)')\n",
    "#     pp.xlim(30, 1024)\n",
    "    \n",
    "    return psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58876b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_template(model,m1,m2,s1z,s2z,conditioned):\n",
    "    \n",
    "    from pycbc.detector import Detector\n",
    "    from pycbc.waveform import get_td_waveform\n",
    "\n",
    "    \n",
    "    ra = 1.7\n",
    "    dec = 1.7\n",
    "    pol = 0.2\n",
    "    inclination_1 = 0\n",
    "    time=0.0\n",
    "\n",
    "\n",
    "\n",
    "    # We can calcualate the antenna pattern for Hanford at\n",
    "    # the specific sky location\n",
    "    d = Detector(\"H1\")\n",
    "\n",
    "    # We get back the fp and fc antenna pattern weights.\n",
    "    fp, fc = d.antenna_pattern(ra, dec, pol, time)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    hp, hc = get_td_waveform(approximant=model,\n",
    "                     mass1=m1,\n",
    "                     mass2=m2,spin1z=s1z,spin2z=s2z,\n",
    "                     delta_t=conditioned.delta_t,\n",
    "                     f_lower=30)\n",
    "    \n",
    "    \n",
    "    ht_template = fp * hp + fc * hc\n",
    "    \n",
    "    #Resizing the template to match data\n",
    "    ht_template.resize(len(conditioned))\n",
    "    \n",
    "    #Time shift \n",
    "    template = ht_template.cyclic_time_shift(ht_template.start_time)\n",
    "    \n",
    "   \n",
    "    return template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47bba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_SNR(template,conditioned,psd):\n",
    "    from pycbc.filter import matched_filter\n",
    "    import numpy\n",
    "\n",
    "    snr = matched_filter(template, conditioned,\n",
    "                         psd=psd, low_frequency_cutoff=30)\n",
    "\n",
    "\n",
    "\n",
    "    # The `matched_filter` function actually returns a 'complex' SNR.\n",
    "    # What that means is that the real portion correponds to the SNR\n",
    "    # associated with directly filtering the template with the data.\n",
    "    # The imaginary portion corresponds to filtering with a template that\n",
    "    # is 90 degrees out of phase. Since the phase of a signal may be \n",
    "    # anything, we choose to maximize over the phase of the signal.\n",
    "\n",
    "   \n",
    "    peak = abs(snr).numpy().argmax()\n",
    "    snrpc= snr[peak]\n",
    "    snrp = abs(snr[peak])\n",
    "    time = snr.sample_times[peak]\n",
    "   \n",
    "    \n",
    "    return snr,time,peak,snrpc,snrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f9108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_chisquare(temp,data,m_1,m_2,s_1,s_2,psd):\n",
    "    \n",
    "    n =int(0.72*pycbc.pnutils.get_freq('fSEOBNRv4Peak',m_1,m_2,s_1,s_2)**0.7)\n",
    "    \n",
    "    chisq = power_chisq(temp, data, n, psd=psd, low_frequency_cutoff=30.0)\n",
    "\n",
    "    # convert to a reduced chisq\n",
    "    chisq /= (n * 2) - 2\n",
    "\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7cbd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_chisq_nsnr(num_templates,data_templates,psd,data,s):\n",
    "\n",
    "    template_info = []\n",
    "\n",
    "    for i in range(num_templates):\n",
    "        T1 = data_templates[i]\n",
    "\n",
    "        S1, time_bns, index_peak_bns, C_snrp, old_snr_bns = gen_SNR(T1,data,psd)\n",
    "        S1.save(f\"Signals_BBH_BNS/snr_complete_series/snr{i}.hdf\")\n",
    "\n",
    "        chisq_1 = gen_chisquare(T1, data, temp_bank[i][0], temp_bank[i][1], s, s, psd)\n",
    "        chisq_val_bns = chisq_1[index_peak_bns]\n",
    "\n",
    "        new_snr_bns = newsnr(abs(S1),chisq_1)\n",
    "\n",
    "        snrp_bns = new_snr_bns[index_peak_bns]\n",
    "\n",
    "        template_info.append([temp_bank[i][0],temp_bank[i][1],time_bns,old_snr_bns,snrp_bns,chisq_val_bns,C_snrp])\n",
    "\n",
    "    return template_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2a0ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recovery(data,n,data_templates,psd): \n",
    "\n",
    "    full__info =  snr_chisq_nsnr(n,data_templates,psd,data,0.8)\n",
    "\n",
    "    info = {}\n",
    "    for i in  full__info:\n",
    "        info.update({i[4] : [i[0],i[1],i[2],i[3],i[5],i[6]]})\n",
    "\n",
    "    snrp_1 = max(info.keys())\n",
    "    time_1 = info.get(max(info.keys()))[2]\n",
    "    m1_1 = info.get(max(info.keys()))[0]\n",
    "    m2_1 = info.get(max(info.keys()))[1]\n",
    "    chi_sq_1 = info.get(max(info.keys()))[4]\n",
    "    Comp_snrp = info.get(max(info.keys()))[5]\n",
    "\n",
    "    print(\"The signal detected is due to the following masses \",m1_1,\"M and \", m2_1, \"M at time \", time_1, \"seconds\", \" with new SNR value as\", snrp_1, \" and chi~square value as \", chi_sq_1 )\n",
    "\n",
    "    return m1_1,m2_1,time_1,snrp_1,full__info,Comp_snrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7e5dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sub(m1_1,m2_1,time_1,com_snrp,data,psd):   \n",
    "    \n",
    "    # The time, amplitude, and phase of the SNR peak tell us how to align\n",
    "    # our proposed signal with the data.\n",
    "\n",
    "    # Shift the template to the peak time\n",
    "    dt = time_1 - data.start_time \n",
    "    \n",
    "    \n",
    "    # if (m1_1 >= 15 and m2_1 >= 15) : \n",
    "    temp_sub  = gen_template('IMRPhenomPv2',m1_1,m2_1,0.8,0.8,data)\n",
    "\n",
    "    # else :\n",
    "    #     temp_sub = gen_template('TaylorF2',m1_1,m2_1,0.05,0.05,data)\n",
    "\n",
    "    aligned = temp_sub.cyclic_time_shift(dt)\n",
    "\n",
    "    # scale the template so that it would have SNR 1 in this data\n",
    "    aligned /= sigma(aligned, psd=psd, low_frequency_cutoff=30.0)\n",
    "\n",
    "    # Scale the template amplitude and phase to the peak value\n",
    "    aligned = (aligned.to_frequencyseries() * com_snrp).to_timeseries()\n",
    "    aligned.start_time = data.start_time\n",
    "\n",
    "    subtracted = data - aligned\n",
    "\n",
    "    psd2 = psd_data(subtracted)  \n",
    "\n",
    "    \n",
    "    return subtracted,psd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4279729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_templates = []\n",
    "\n",
    "for i in range(20):\n",
    "    T = timeseries.load_timeseries(f\"Signals_BBH_BNS/signal_bbh{i}.hdf\")\n",
    "    data_templates.append(T)\n",
    "\n",
    "for i in range(20):\n",
    "    R = timeseries.load_timeseries(f\"Signals_BBH_BNS/signal_bns{i}.hdf\")\n",
    "    data_templates.append(R)\n",
    "\n",
    "temp_bank = pd.read_csv('Signals_BBH_BNS/Load_bbh_bns.csv')\n",
    "temp_bank = temp_bank.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1eae7a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for j in range(1):\n",
    "    \n",
    "    print(\"Recovery number:\",j)\n",
    "    print(' ')\n",
    "    \n",
    "    ts1 = timeseries.load_timeseries(f\"Signals_BBH_BNS/Data_{j}.hdf\")\n",
    "    psd1 = psd_data(ts1)  \n",
    "    mass_1,mass_2,time,snrp,total,j_snrp = recovery(ts1,40,data_templates,psd1)\n",
    "    \n",
    "    print(' ')\n",
    "\n",
    "\n",
    "#     for i in range(5):\n",
    "\n",
    "#         sub,psd_sub = align_sub(mass_1,mass_2,time,j_snrp,ts1,psd1)\n",
    "#         M1,M2,T,SP,Tot,k_snrp = recovery(sub,200,data_templates,psd_sub)\n",
    "#     #     pp.plot(sub.sample_times,sub)\n",
    "#     #     pp.xlim(1.6,2.0)\n",
    "#     #     pp.show()\n",
    "#         mass_1=M1\n",
    "#         mass_2=M2\n",
    "#         time=T\n",
    "#         snrp=SP\n",
    "#         j_snrp = k_snrp\n",
    "#         total.extend([[0,0,0,0,0,0]])\n",
    "#         total.extend(Tot)\n",
    "\n",
    "#         print(\" \")\n",
    "#     print(\"-----------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe76f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_B1 = data_templates[2]\n",
    "T_B1_MF = timeseries.load_timeseries(f\"Signals_BBH_BNS/snr_complete_series/snr{2}.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c18b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_total_info = pd.DataFrame(total,columns = ['M1','M2','Time','Old_SNR','New_SNR','Chi-Sq.','Comp_Snr'])\n",
    "# df_total_info.to_excel('100_Inj_Rec.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab9de03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "B = []\n",
    "maxim_SNR = []\n",
    "\n",
    "for i in range(40):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    if i != 2:\n",
    "\n",
    "        cross = matched_filter(data_templates[i], T_B1,\n",
    "                         psd=psd1, low_frequency_cutoff=30)\n",
    "\n",
    "        T_N1_MF = timeseries.load_timeseries(f\"Signals_BBH_BNS/snr_complete_series/snr{i}.hdf\")\n",
    "\n",
    "        A_B1 = (T_B1_MF - (cross*T_N1_MF))/(1-(cross**2))\n",
    "        A.append(A_B1)\n",
    "\n",
    "        A_N1 = (T_N1_MF - (cross*T_B1_MF))/(1-(cross**2))\n",
    "        B.append(A_N1)\n",
    "\n",
    "        norm = (A_B1**2) + (A_N1**2) + 2*(A_B1*A_N1*cross)\n",
    "        SNR = ((A_B1*T_B1_MF) + ( A_N1 * T_N1_MF))/norm\n",
    "        peak_SNR = abs(SNR).numpy().argmax()\n",
    "        SNR_p = abs(SNR[peak_SNR])\n",
    "        maxim_SNR.append([i,SNR_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf0d5b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "4\n",
      "11\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "M_SNR = 0\n",
    "for i in range(len(maxim_SNR)):\n",
    "    if M_SNR < maxim_SNR[i][1]:\n",
    "        M_SNR = maxim_SNR[i][1]\n",
    "        print(maxim_SNR[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b6a7d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000003952\n"
     ]
    }
   ],
   "source": [
    "print(maxim_SNR[32][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a4b3eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1.000000000000099], [1, 1.0000000000000748], [3, 1.000000000000139], [4, 1.0000000000002458], [5, 1.0000000000000373], [6, 1.0000000000000921], [7, 1.0000000000000357], [8, 1.00000000000006], [9, 1.0000000000000577], [10, 1.0000000000000455], [11, 1.0000000000002645], [12, 1.00000000000016], [13, 1.0000000000001117], [14, 1.0000000000000586], [15, 1.0000000000000484], [16, 1.0000000000000642], [17, 1.0000000000000586], [18, 1.0000000000000449], [19, 1.0000000000000278], [20, 1.0000000000000153], [21, 1.0000000000000762], [22, 1.000000000000045], [23, 1.0000000000000615], [24, 1.0000000000000502], [25, 1.000000000000038], [26, 1.0000000000001483], [27, 1.0000000000000302], [28, 1.0000000000000564], [29, 1.0000000000000557], [30, 1.0000000000000118], [31, 1.000000000000026], [32, 1.0000000000000493], [33, 1.0000000000003952], [34, 1.0000000000000226], [35, 1.0000000000000195], [36, 1.0000000000000442], [37, 1.0000000000000413], [38, 1.0000000000000755], [39, 1.0000000000000837]]\n"
     ]
    }
   ],
   "source": [
    "print(maxim_SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278fa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
